<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Davide Boscaini</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM" crossorigin="anonymous">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="stylesheet" href="custom.css">
  </head>

  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
      <div class="container">
        <a class="navbar-brand">Davide <strong>Boscaini</strong></a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav me-auto mb-2 mb-lg-0">
            <li class="nav-item">
              <a class="nav-link" aria-current="page" href="index.html">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" href="publications.html">Publications</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container my-5">


      <h2>Bibliometrics</h2>
      <div class="container">
        <a class="btn btn-outline-dark btn-sm" href="https://scholar.google.com/citations?user=dT1N2IUAAAAJ&amp;hl=en&amp;oi=ao">
          <i class="ai ai-google-scholar ai-2x" style="vertical-align: middle"></i> Google Scholar
        </a>
        <a class="btn btn-outline-dark btn-sm" href="https://www.semanticscholar.org/author/D.-Boscaini/1804261">
          <i class="ai ai-semantic-scholar ai-2x" style="vertical-align: middle"></i> Semantic Scholar
        </a>
        <a class="btn btn-outline-dark btn-sm" href="https://dblp.org/pid/129/6623.html">
          <i class="ai ai-dblp ai-2x" style="vertical-align: middle"></i> dblp
        </a>
        <a class="btn btn-outline-dark btn-sm" href="https://orcid.org/0000-0003-4887-2038">
          <i class="ai ai-orcid ai-2x" style="vertical-align: middle"></i> orcid
        </a>
      </div>
      <br><br>


      <!-- 2024 -->
      <hr class="col col-lg-2">
      <ul class="list-group list-group-flush">
        <h2>2024 papers</h2>

        <!-- ECCV 2024 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2024_ECCV_FreeZe.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">FreeZe: Training-free zero-shot 6D pose estimation with geometric and vision foundation models</h5>
          </div>
          <p class="mb-1">Andrea Caraffa, <strong>Davide Boscaini</strong>, Amir Hamza, Fabio Poiesi</p>
          <p class="mb-1"><i>European Conference on Computer Vision (ECCV)</i>, 2024</p>
            <!-- &mdash; <font color="#a21a2a">Highlight poster (2.8% acceptance rate)</font></p> -->
          <p class="mb-1"><font color="#899499">Awards: An early version</a> of this work won the "Best method on TUD-L dataset" award at the BOP Challenge 2023.</font></p>
            <!-- <a href="https://bop.felk.cvut.cz/method_info/386/"></a> -->
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://andreacaraffa.github.io/freeze/">
            <i class="fa fa-globe"></i>&nbsp;&nbsp;webpage
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2312.00947">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://bop.felk.cvut.cz/leaderboards/pose-estimation-unseen-bop23/bop-classic-core/">
            <i class="fa fa-trophy"></i>&nbsp;&nbsp;BOP leaderboard
          </a>
          <!-- <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/andreacaraffa/freeze">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a> -->
          <p></p>
        </li>

        <!-- CVPR 2024 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2024_CVPR_Oryon.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Open-vocabulary object 6D pose estimation</h5>
          </div>
          <p class="mb-1">Jaime Corsetti, <strong>Davide Boscaini</strong>, Changjae Oh, Andrea Cavallaro, Fabio Poiesi</p>
          <p class="mb-1"><i>Computer Vision and Pattern Recognition (CVPR)</i>, 2024
            &mdash; <font color="#a21a2a">Highlight poster (2.8% acceptance rate)</font></p>
          <p class="mb-1"><font color="#899499">TL;DR: We introduce the new setting of open-vocabulary object 6D pose estimation,
            in which a textual prompt is used to specify the object of interest,
            instead of requiring its 3D model or a video footage capturing multiple viewpoints around the object.</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://jcorsetti.github.io/oryon/">
            <i class="fa fa-globe"></i>&nbsp;&nbsp;webpage
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2312.00690">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/jcorsetti/oryon">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>
      </ul>

      <!-- 2023 -->
      <hr class="col col-lg-2">
      <ul class="list-group list-group-flush">
        <h2>2023 papers</h2>

        <!-- BMVC 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_BMVC_DACA.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Detect, Augment, Compose, and Adapt: Four steps for unsupervised domain adaptation in object detection</h5>
          </div>
          <p class="mb-1">Mohamed L. Mekhalfi, <strong>Davide Boscaini</strong>, Fabio Poiesi</p>
          <p class="mb-1"><i>British Machine Vision Conference (BMVC)</i>, 2023</p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2308.15353">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/mohamedtev/daca">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>

        <!-- ICCV-W 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_ICCVW_FCGF6D.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Revisiting Fully Convolutional Geometric Features for object 6D pose estimation</h5>
          </div>
          <p class="mb-1">Jaime Corsetti, <strong>Davide Boscaini</strong>, Fabio Poiesi</p>
          <p class="mb-1"><i>International Workshop on Recovering 6D Object Pose (R6D)</i>, 2023
            &mdash; <font color="#a21a2a">Held in conjunction with ICCV 2023</font></p>
          <!-- <p class="mb-1"><font color="#899499">TLDR: TBD.</font></p> -->
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2307.15514">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/jcorsetti/FCGF6D">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>

        <!-- IMAVIS 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_IMAVIS_PatchMixer.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">PatchMixer: Rethinking network design to boost generalization for 3D point cloud understanding</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Fabio Poiesi</p>
          <p class="mb-1"><i>Image and Vision Computing (IMAVIS)</i>, 2023</p>
          <p class="mb-1"><font color="#899499">TL;DR: We introduce a novel network design that demonstrates strong generalization performance across datasets unseen during training. 
            PatchMixer achieves SOTA classification performance on the GraspNetPC dataset in the transfer learning setting</font></p>
          <a class="btn btn-outline-dark btn-sm"  style="margin-top:3px" href="https://www.sciencedirect.com/science/article/abs/pii/S0262885623001427">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;<strong>pdf</strong>
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2307.15692">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;<strong>arxiv</strong>
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/davideboscaini/PatchMixer">
            <i class="fa fa-github"></i>&nbsp;&nbsp;<strong>code</strong>
          </a>
          <p></p>
        </li>

        <!-- MIA 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_MIA.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Supervised tractogram filtering using Geometric Deep Learning</h5>
          </div>
          <p class="mb-1">Pietro Astolfi, Ruben Verhagen, Laurent Petit, Emanuele Olivetti, Silvio Sarubbo, Jonathan Masci, <strong>Davide Boscaini</strong>, Paolo Avesani</p>
          <p class="mb-1"><i>Medical Image Analysis (MIA)</i>, 2023</p>
          <!-- <p class="mb-1"><font color="#899499">TLDR: First geometric deep learning application to the problem of .</font></p> -->
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523001536?via%3Dihub">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2212.03300">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <p></p>
        </li>

        <!-- CVPR-W 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_CVPRW_MONET.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">The MONET dataset: Multimodal drone thermal dataset recorded in rural scenarios</h5>
          </div>
          <p class="mb-1">Luigi Riz, Andrea Caraffa, Matteo Bortolon, Mohamed L. Mekhalfi, <strong>Davide Boscaini</strong>, André Moura, José Antunes, André Dias, Hugo Silva, Andreas Leonidou, Christos Constantinides, Christos Keleshis, Dante Abate, Fabio Poiesi</p>
          <p class="mb-1"><i>Multimodal Learning and Applications Workshop (MULA)</i>, 2023
            &mdash; <font color="#a21a2a">Held in conjunction with CVPR 2023</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2304.05417">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/fabiopoiesi/monet_dataset">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>

        <!-- TPAMI 2023 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2023_PAMI_GeDi.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Learning general and distinctive 3D local deep descriptors for point cloud registration</h5>
          </div>
          <p class="mb-1">Fabio Poiesi, <strong>Davide Boscaini</strong></p>
          <p class="mb-1"><i>Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2023</p>
          <p class="mb-1"><font color="#899499">TL;DR: State-of-the-art performance for point cloud registration in the transfer learning setting across 3DMatch, ETH, and Kitti datasets</font></p>

          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2105.10382">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/fabiopoiesi/gedi">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>
      </ul>

      <!-- Until 2022 -->
      <hr class="col col-lg-2">
      <ul class="list-group list-group-flush">
        <h2>Papers until 2022</h2>

        <!-- ICPR-W 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_ICPRW.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Localisation of defects in volumetric CT scans of valuable wood logs</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Fabio Poiesi, Stefano Messelodi, Ayman Younes, Donato A. Grande</p>
          <p class="mb-1"><i>International Workshop on Industrial Machine Learning (IML)</i>, 2020
            &mdash; <font color="#a21a2a">Held in conjunction with ICPR 2020, Oral presentation</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://dl.acm.org/doi/abs/10.1007/978-3-030-68799-1_50">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <p></p>
        </li>

        <!-- ICPR 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_ICPR_Puzzle.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Joint supervised and self-supervised learning for 3D real-world challenges</h5>
          </div>
          <p class="mb-1">Antonio Alliegro, <strong>Davide Boscaini</strong>, Tatiana Tommasi</p>
          <p class="mb-1"><i>International Conference on Pattern Recognition (ICPR)</i>, 2020
            &mdash; <font color="#a21a2a">Oral presentation (4.4% acceptance rate)</font></p>
        </li>

        <!-- ICPR 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_ICPR_DIP.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Distinctive 3D local deep descriptors</h5>
          </div>
          <p class="mb-1">Fabio Poiesi, <strong>Davide Boscaini</strong></p>
          <p class="mb-1"><i>International Conference on Pattern Recognition (ICPR)</i>, 2020</p>
        </li>

        <!-- ICPR 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_ICPR_2DKeyEst.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Shape consistent 2D keypoint estimation under domain shift</h5>
          </div>
          <p class="mb-1">Levi O. Vasconcelos, Massimiliano Mancini, <strong>Davide Boscaini</strong>, Samuel Rota Bulò, Barbara Caputo, Elisa Ricci</p>
          <p class="mb-1"><i>International Conference on Pattern Recognition (ICPR)</i>, 2020</p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://ieeexplore.ieee.org/document/9411982">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2008.01589">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
        </li>

        <!-- ACCV 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_ACCV_NovelView.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Novel-view human action synthesis</h5>
          </div>
          <p class="mb-1">Mohamed I. Lakhal, <strong>Davide Boscaini</strong>, Fabio Poiesi, Oswald Lanz, Andrea Cavallaro</p>
          <p class="mb-1"><i>Asian Conference on Computer Vision (ACCV)</i>, 2020</p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2007.02808">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
        </li>

        <!-- IJCB 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_IJCB.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Clustered dynamic graph CNN for biometric 3D hand shape recognition</h5>
          </div>
          <p class="mb-1">Jan Svoboda, Pietro Astolfi, <strong>Davide Boscaini</strong>, Jonathan Masci, Michael M. Bronstein</p>
          <p class="mb-1"><i>International Joint Conference on Biometrics (IJCB)</i>, 2020</p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://ieeexplore.ieee.org/document/9304894">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <p></p>
        </li>

        <!-- MICCAI 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_MICCAI.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Tractogram filtering of anatomically non-plausible fibers with Geometric Deep Learning</h5>
          </div>
          <p class="mb-1">Pietro Astolfi, Ruben Verhagen, Laurent Petit, E. Olivetti, Jonathan Masci, <strong>Davide Boscaini</strong>, Paolo Avesani</p>
          <p class="mb-1"><i>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</i>, 2020
            &mdash; <font color="#a21a2a">First Geometric Deep Learning application to NeuroImaging tasks</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2003.11013">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <p></p>
        </li>

        <!-- ECCV-W 2020 -->
        <li class="list-group-item list-group-item-action">
          <!-- <figure class="figure">
            <img src="data/thumb/2020_ECCVW.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure> -->
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Self-supervision for 3D real-world challenges</h5>
          </div>
          <p class="mb-1">Antonio Alliegro, <strong>Davide Boscaini</strong>, Tatiana Tommasi</p>
          <p class="mb-1"><i>Multimodal Learning and Applications Workshop (MULA)</i>, 2020
            &mdash; <font color="#a21a2a">Held in conjunction with ECCV 2020</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://link.springer.com/chapter/10.1007/978-3-030-66415-2_48">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <p></p>
        </li>

        <!-- Nature Methods 2020 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2020_nature_methods.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Deciphering interaction fingerprints from protein molecular surfaces using Geometric Deep Learning</h5>
          </div>
          <p class="mb-1">Pablo Gainza, Freyr Sverrisson, Federico Monti, Emanuele Rodolà, <strong>Davide Boscaini</strong>, Michael M. Bronstein, Bruno E. Correia</p>
          <p class="mb-1"><i>Nature Methods</i>, 2020
            &mdash; <font color="#a21a2a">Advertised on the February 2020 cover</font></p>
          <p></p>
        </li>

        <!-- NeurIPS-W 2019 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2019_neurips_workshop.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Learning interaction patterns from surface representations of protein structure</h5>
          </div>
          <p class="mb-1">Pablo Gainza, Freyr Sverrisson, Federico Monti, Emanuele Rodolà, <strong>Davide Boscaini</strong>, Michael M. Bronstein, Bruno E. Correia</p>
          <p class="mb-1"><i>NeurIPS Workshop on Graph Representation Learning</i>, 2019
            &mdash; <font color="#a21a2a">Held in conjunction with NeurIPS 2019</font></p>
          <p></p>
        </li>

        <!-- 3DV 2019 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2019_sda.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Structured domain adaptation for 3D keypoint estimation</h5>
          </div>
          <p class="mb-1">Levi O. Vasconcelos, Massimiliano Mancini, <strong>Davide Boscaini</strong>, Barbara Caputo, Elisa Ricci</p>
          <p class="mb-1"><i>International Conference on 3D Vision (3DV)</i>, 2019
              &mdash; <font color="#a21a2a">Oral presentation</font></p>
          <p></p>
        </li>

        <!-- ICIAP 2019 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2019_segm.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">3D shape segmentation with Geometric Deep Learning</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Fabio Poiesi</p>
          <p class="mb-1"><i>International Conference on Image Analysis and Processing (ICIAP)</i>, 2019
            &mdash; <font color="#a21a2a">Spotlight presentation</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/2002.00397">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <p></p>
        </li>

        <!-- CVPR 2017 -->
        <li class="list-group-item list-group-item-action"> <!--flex-column align-items-start-->
          <figure class="figure">
            <img src="data/thumb/2017_monet.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Geometric deep learning on graphs and manifolds using mixture model CNNs</h5>
          </div>
          <p class="mb-1">Federico Monti<font color="#899499">*</font>, <strong>Davide Boscaini</strong><font color="#899499">*</font>, Jonathan Masci, Emanuele Rodolà, Jan Svoboda, Michael M. Bronstein 
            &emsp; <font color="#899499">(* denotes equal contibution)</font></p>
          <p class="mb-1"><i>Computer Vision and Pattern Recognition (CVPR)</i>, 2017
              &mdash; <font color="#a21a2a">Oral presentation (0.8% acceptance rate)</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://drive.google.com/file/d/1my9DIHRgwcBtz6edjRYrWYX65FW16xR3/view?usp=sharing">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/1611.08402">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <p></p>
        </li>

        <!-- NeurIPS 2016 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2016_acnn_nips.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height: 120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Learning shape correspondence with anisotropic convolutional neural networks</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Jonathan Masci, Emanuele Rodolà, Michael M. Bronstein</p>
          <p class="mb-1"><i>Neural Information Processing Systems (NeurIPS)</i>, 2016</p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://drive.google.com/file/d/144zT0gGZY9JyfeQR0jusS181tCKDuSrG/view?usp=sharing">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://arxiv.org/abs/1605.06437">
            <i class="ai ai-arxiv ai-1x"></i>&nbsp;&nbsp;arxiv
          </a>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://github.com/davideboscaini/acnn">
            <i class="fa fa-github"></i>&nbsp;&nbsp;code
          </a>
          <p></p>
        </li>

        <!-- EG 2016 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2016_add.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Anisotropic diffusion descriptors</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Jonathan Masci, Emanuele Rodolà, Michael M. Bronstein, Daniel Cremers</p>
          <p class="mb-1"><i>Computer Graphics Forum (CGF)</i>, 2016
            &mdash; <font color="#a21a2a">Oral presentation at Eurographics 2016</font></p>
          <a class="btn btn-outline-dark btn-sm" style="margin-top:3px" href="https://drive.google.com/file/d/16xwzZCNSs2KwO78horEVBAjhfQWR2vio/view?usp=sharing">
            <i class="fa fa-file-pdf-o" aria-hidden="true"></i>&nbsp;&nbsp;pdf
          </a>
          <p></p>
        </li>

        <!-- SGP 2015 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2015_lscnn.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Jonathan Masci, Simone Melzi, Michael M. Bronstein, Umberto Castellani, Pierre Vandergheynst</p>
          <p class="mb-1"><i>Computer Graphics Forum (CGF)</i>, 2015
            &mdash; <font color="#a21a2a">Oral presentation at SGP 2015</font></p>
        </li>

        <!-- ICCV-W 2015 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2015_gcnn_iccvw.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Geodesic convolutional neural networks on Riemannian manifolds</h5>
          </div>
          <p class="mb-1">Jonathan Masci<font color="#899499">*</font>, <strong>Davide Boscaini</strong><font color="#899499">*</font>, Michael M. Bronstein, Pierre Vandergheynst
            &emsp; <font color="#899499">(* denotes equal contibution)</font></p>
          <p class="mb-1"><i>ICCV Workshop on 3D Representation and Recognition (3dRR)</i>, 2015
            &mdash; <font color="#a21a2a">Oral presentation</font></p>
        </li>

        <!-- EG 2015 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2015_sfo.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Shape-From-Operator: Recovering shapes from intrisic operators</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Davide Eynard, Drosos Kourounis, Michael M. Bronstein</p>
          <p class="mb-1"><i>Computer Graphics Forum (CGF)</i>, 2015
            &mdash; <font color="#a21a2a">Oral presentation at Eurographics 2015</font></p>
        </li>

        <!-- 3DOR 2014 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2014_coulomb.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Coulomb shapes: Using electrostatic forces for deformation-invariant shape representation</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Ramunas Girdziusaz, Michael M. Bronstein</p>
          <p class="mb-1"><i>Eurographics Workshop on 3D Object Retrieval (3DOR)</i>, 2014
            &mdash; <font color="#a21a2a">Oral presentation</font></p>
        </li>

        <!-- TVC 2014 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2014_asc.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">A sparse coding approach for local-to-global 3D shape description</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Umberto Castellani</p>
          <p class="mb-1"><i>The Visual Computer (TVC)</i>, 2014</p>
        </li>

        <!-- 3DOR 2013 -->
        <li class="list-group-item list-group-item-action">
          <figure class="figure">
            <img src="data/thumb/2013_lsq.png" class="figure-img img-fluid border rounded-0" alt="Paper thumbnail" style="min-height:90px; max-height:120px">
          </figure>
          <div class="d-flex w-100 justify-content-between" style="margin-top:-10px">
            <h5 class="mb-1">Local signature quantization by sparse coding</h5>
          </div>
          <p class="mb-1"><strong>Davide Boscaini</strong>, Umberto Castellani</p>
          <p class="mb-1"><i>Eurographics Workshop on 3D Object Retrieval (3DOR)</i>, 2013
            &mdash; <font color="#a21a2a">Oral presentation</font></p>
        </li>

      </ul>

    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-geWF76RCwLtnZ8qwWowPQNguL3RmwHVBC9FhGdlKrxdiJJigb/j/68SIy3Te4Bkz" crossorigin="anonymous"></script>
  </body>
</html>
